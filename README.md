# game render loop vr injector
Library that finds the render function in a x64 executable.

The Library is built on the call trace project.
A project or tool or whatever that traces function calls in an executable by using breakpoints.

## The call trace project

For reverse engineering it would be useful to get the exact call trace of a binary
Exactly what jumps where what sections of code calls what addresses and so on.

This information would allow one to find where functions are located in the code. Even if you did not have debug symbols.
Compilation optimisations might make this impossible in some cases. But in some cases it should work.

There are various tools that promise this ability. None of them work except for simple binaries.

### Dynamic instrumentation tools
Due to the emense classic nr of instructions that need to be tracked implementing such feature with a classic debugger is to slow.
The solution to this is a Dynamic instrumentation tool. These exist but are complex beasts.
On linux you have callgrind a part of the valgrind project. Which should work in wine but does not for some reason. On windows you have DynamoRIO.

There is also a tool called frida that allows you to inject javascript in to any x86 binary. But it is slow and crashy.

I have been unable to get callgrind to work partly due to how modern games tend to use launchers that verify the executable. I have not been able to use DynamoRIO mostly cause i struggle to understand where to begin.

I would like to be able to attach after the process has spawned either by replacing a dll or simply by attaching a debugger to the process id.

## trace.py
trace.py traces all calls and rets in a function. Earlier versions tried to use shortcuts but they all had various issues. The point of trace.py is to as good as you are going to get a call tracer when it comes to accuracy. Speed is important but it suposed to be refernce for accuracy.

The main call tracing in trace.py is built on four types of breakpoints.
1. Making a call. Each call instruction gets a breakpoint.
2. Returning from a call. All instructions directly following a call gets a breakpoint.
3. Entering a function. The entrypoint of each function gets a breakpoint.
4. Exiting a function. Each ret instruction gets a breakpoint.

Breakpoint type 1 & 2 are the most important ones. You can trace an executable without type 3 & 4 but the trace will be less accurate. If you miss type 3 and not type 4 you may miss certain callbacks from external libraries (callbacks to certain functions that dont have their own ret instruction) and you will not be able to capture arguments to callbacks and the order of callbacks will be imposible to recover in certain cases. If you miss type 3 & 4 you may again miss certain callbacks and again no arguments. If you miss type 4 but not type 3 you will miss certain callbacks to that are executed more than once.

Breakpoint type 3 is only made posible when you have a function map a map that declares where each function starts. On linux a function map can be generated by scaning the executable for entry instructions (that inserts framepointers) on windows (which trace.py is primarly made for) this map is found in the .pdata section of the executable/module. You can also dynamicly generate a partial function map by running the executable with breakpoint type 1 & 2 and recording all call targets which may be usefull if you dont have entry instrucitons or the .pdata table has been striped.

#### Non obvoius issues
Are entires in the .pdata section trully functions? Ie does the stack pointer always point to the return address on execution entry in to a .pdata section.
I know they are not allwys called direcly but sometimes they are jumped to.

Certain functions dont use their own ret instruction but jump to a external library and let that library return. This means that a entry breakpoint may not allways be paired with a exit breakpoint. Since a function can contain a jump to its own entry we only count the first time a entry breakpoint is made and this count is reset when exiting the function. This means that functions that dont have their own ret and are used as callbacks more than once in a row is imposible to track. This could be solved by putting a hardware breakpoint on the memmory address of the return address. But then we need to know the true return address.

But this goes back to hte first point we cant know if a entry in to a function that is not directly preceded by a traced call is actually a call and if the stack pointer is thus pointing to a return address. It may be a jump that preceded the entry. If it is there is no return address then the stack pointer will be pointing to some random address that is not the function return address at all.


##### Some improvments
- One thing that can be done that works 100% of the time is to single step the execution, but that is simply to slow. So is not an improvment.
- Adding a memmory access hardwarebreakpoint on access to the stack. This might be a good idea, but threding might be problematic.
- If you are exiting from an external callback and the stackpointer is larger than it was on you last breakpoint then you know the callback was made from somewhere inside that last call. Mabye it is true that the call back was made from inside the last API i call regadless of the stackpointer. But mabye interupts could be a counter example but i dont know how they work on x64. This cant be done as there are many calls that use alternative stacks for callbacks.

## Making it fast
Instead of breakpoints we need to alter the opcodes and wrap functions and add jump to tables and stuff like that.

For breakpoint type 1 and 2 this revolves around replacing call instructions with instructions that allow us to wrap the call instruction.
calls that are 5 bytes or longer are easy to replace you simply switch them out for a jump to a place where you can do whatever you want then jump back.

For calls that are 2 and 3 bytes long it gets tricker. The only jump you can fit in that is a short jump (which is 2 bytes long), a short jump only allows jumping forward or backwards 127 bytes.
And 127 bytes is not enogh to jump to a place where there is free memmory.

I see two posible solutions to this; both of them have issues.

1. Use the area of the instructions just ahead of the call.
   For example the instructions:
   ```
   48 8b 01        MOV        RAX,qword ptr [param_1->unused]
   0e ff 10        CALL       qword ptr [RAX]
   ```
Gives you 6 usable bytes those instructions can be moved a new area and a jump can be inserted to that area.
This requires that the instructions are not doing relative jumps or have recerences to RIP (lets call these replacable instructions).
It also requires that no other code jumps direcly to the call. Cause after replacement that jump will end up in the midle of an instruction.

2. The other way to solve this is to ove the call instruction to a new memory region where it can be wraped. Then to search the surunding area of the call for replacable instructions. Then we move those instructions to a new memmory region and insert jump to the new memmory region and second jump to where wraped call is the area of the replaced instrucitons. Finnaly we replace the orginal call and place a shortjump to the long call of the wraped call instruction. This has the same issue as the first one, that jumps to thes instructions will fail result in segfaults.

The first one will proably work for most places.
And using a breakpoint for the new places where we cant find a solution can work as a fallback.


## Work so far

### Branch tracing

Initially i tried implementing this as a full fledged dynamic instrumentation tool on top of a debugger. This code is located in [track_calls_using_instruction_tracing.py](track_calls_using_instruction_tracing.py) Instead of stepping each instruction in the debugger, decompiles blocks of the executable and adds breakpoints att all branches. Then when it gets to those branches it adds new breakpoints. This continues forever.
This proved to be to slow, especially considering the use of python(which is very slow) as the debugger scripting engine.

### Call tracing
Th file [track_calls_using_debug_events.py](track_calls_using_debug_events.py) also traces using breakpoints but it decompiles the entire executable module by module on startup then adds breakpoints on the main executable calls and returns. This has proved to be an effective learning platform. However it will not work if the executable is using self-modifying code.

Both of these implementations have issues with multithreaded code as the debugger will catch any thread and the code has not been written to take that in to account.


We also have [trace_basic.py](trace_basic.py) trace_basic.py uses the Pdata to find and add breakpoints at the start och each function and then it disasembles each function and ads breakpoints at all ret(return) instrucitons.

### next step
I have been thinking of new solution that does not capture the call trace as it happens.
It works in reverse based on the assumption that the code you are interested in will run in a loop.

Basically you start by selecting a API call to a dll (direct X) for example.
1. You add a breakpoint in that API call.
2. You look at the return adress then decompile from that adress forward until you hit a ret instruction. (techinically this might fail as the code may jump away so technically you need to trace every jump after this. But assuming a normal boring compiler just decompiling from that point untill there is ret should work)
3. You add a breakpoint at that ret instruction
4. When that breakpoint hits, you obtain the return address from the stack which is from where the current function was called.
5. Then you step one instruction back from that return address and add a breakpoint.
6. Now we hope that the function is run in a loop and that the breakpoint is called again.
7. When these breakpoints hit this is when we now where the calling function starts.
8. Rinse and repeat until you are at the top level.

You may want to capture multiple of each break point as each function may be called from multiple locations.

### Update
Built the loop based tracer see [track_calls_backwards_from_dll.py](track_calls_backwards_from_dll.py)
It works as good as it will work. The issue that makes it not work quite right is that the return address is not allways corect.
Pressumably there are places where there are jumps to the begining of a function this makes it so that the top of the stack is not always a return address when the begining of a function hits. Or some function is purposly manipulating the stack.

To solve this you would need to trace at the location of call rather than in the function beeing called.

PS. None of these methods will capture call backs in a good way.

If we are tracing at the call we could probably speed things upp by not using breakpoins but instead allter the call so that it goes to a location in the empty space infront of the function. That way we can track the function with a native funcion that is being called or jumped to from that place. DynamoRIO is starting to look quite nice at this point.



## Current work

- [x] The symbol loader from winappdbg is extremely slow and very very bad it almost never finds the true function. Implemented a new symbol loader which loads .pdb files.
- [x] Initially we looked at directX 9 due to its simplicity, we need to start looking at the reversing of dx11. Maybe we should build a text dx11 project.
- [ ] We will want to be able to decode the arguments of the API functions we add breakpoints to so that we can differentiate different rendering passes for example. Need to figure out how to do that.
- [X] Implement the loop based debugger


# Stereo injection
Many stereo injection plugins for games does alternative frame rendering; that is they don't alter the games render code. The mods simply move the camera every other frame and sends every other frame to each eye.
This causes almost instant nausea and is a horrible experience. It is better to simply not have stereoHead tracking at all. Head tracking is 80% of the experience so if you can manage that it is often enough.

The beter way is to actually render the game twice. This can be done in two ways.
* Traditional Rendering:
In a basic setup, you’d indeed update the view/projection matrices for each eye and issue separate draw calls. This means the scene is rendered twice—once for each eye.
* Single-Pass Stereo (Multi-View Rendering):
With advanced techniques, you can leverage multiple viewports along with instancing. In single-pass stereo, you submit your geometry once and use the GPU to transform it twice (or more) for each eye, each using a different viewport and camera matrix. This reduces CPU overhead by avoiding multiple draw calls even though conceptually, two different views are being produced.

Both generate the same image but **Single-Pass Stereo** is more efficient so will in theory allow for higher FPS. But it can also be allot harder to patch in since you need to modify shader code as well as the normal game code. **Traditional Rendering** may be easy to pull off depending argumentson how the games rendering works.
If you are lucky like in the example dx11 file in [example_simple_dx11_render.cpp](example_simple_dx11_render.cpp) you have a clean render function all you need to do is find it, change the camera matrix and run the function an extra time on each loop.
If you are not able to do that you need to capture all DX11 calls.
Then either save their buffers and argumensts then run them again or copy all the arguments and buffers and simultaneously run them in a different dx11 instance.

